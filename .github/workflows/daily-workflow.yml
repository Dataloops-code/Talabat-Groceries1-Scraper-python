name: Daily Talabat Groceries Scraper

on:
  schedule:
    - cron: "0 */6 * * *"  # Runs every 6 hours
  workflow_dispatch:     # Allows manual triggering

jobs:
  scrape:
    runs-on: ubuntu-latest
    timeout-minutes: 120  # Adjusted to 2 hours, tweak as needed
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
        with:
          token: ${{ secrets.GITHUB_TOKEN }}
          ref: master  # Assuming 'master' is your default branch; adjust if it's 'main'

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.10"

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt  # Installs all dependencies including Google libraries

      - name: Install Playwright Browsers
        run: |
          python -m playwright install chromium firefox

      - name: Install Playwright System Dependencies
        run: |
          sudo apt-get update
          sudo apt-get install -y libdbus-glib-1-2 libgtk-3-0 libgdk-pixbuf2.0-0 libxcomposite1 libxdamage1 libxrandr2 libgbm1 libpcre3 libwoff1 libevent-2.1-7 libopus0 libsecret-1-0 libhyphen0 libgles2 libsoup2.4-1 libvpx-dev

      - name: Restore cached progress
        id: cache-restore
        uses: actions/cache/restore@v4
        with:
          path: |
            current_progress.json
          key: talabat-groceries-progress-${{ github.run_id }}
          restore-keys: |
            talabat-groceries-progress-

      - name: Run Talabat Groceries Scraper
        run: |
          python main.py
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
          TALABAT_GCLOUD_KEY_JSON: ${{ secrets.TALABAT_GCLOUD_KEY_JSON }}

      - name: Debug file presence
        if: always()
        run: |
          ls -la
          cat current_progress.json || echo "current_progress.json not found"
          cat scraped_progress.json || echo "scraped_progress.json not found"
          ls output/الاحمدي_groceries.xlsx || echo "الاحمدي_groceries.xlsx not found"

      - name: Commit progress updates
        if: always()
        run: |
          git config --global user.name "GitHub Action"
          git config --global user.email "action@github.com"
          git add current_progress.json scraped_progress.json output/ || true  # Proceed even if files are missing
          git commit -m "Update scraper progress and data for run ${{ github.run_id }}" || echo "No changes to commit"
          git push
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}

      - name: Save progress to cache
        if: always()  # Run even if previous steps fail/cancel
        uses: actions/cache/save@v4
        with:
          path: |
            current_progress.json
          key: talabat-groceries-progress-${{ github.run_id }}

      - name: Upload progress artifacts
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: talabat-groceries-progress-files
          path: |
            current_progress.json
            scraped_progress.json
            output/
            scraper.log
          retention-days: 7

      - name: Cleanup
        if: always()
        run: |
          rm -rf ~/.cache/ms-playwright
          

# name: Daily Workflow

# on:
#   workflow_dispatch:

# concurrency:
#   group: workflow-group
#   cancel-in-progress: true

# jobs:
#   scrape:
#     runs-on: ubuntu-latest
#     timeout-minutes: 2000
#     steps:
#       - name: Checkout Repository
#         uses: actions/checkout@v4
        
#       - name: Set up Python
#         uses: actions/setup-python@v5
#         with:
#           python-version: '3.10'
          
#       - name: Install Dependencies
#         run: |
#           python -m pip install --upgrade pip
#           pip install -r requirements.txt
          
#       - name: Install Playwright for Python
#         run: |
#           pip install playwright
#           python -m playwright install
#           python -m playwright install firefox  # Install Firefox browser
#           python -m playwright install webkit

#       - name: Install Playwright Dependencies
#         run: |
#           sudo apt-get update
#           sudo apt-get install -y libdbus-glib-1-2 libgtk-3-0 libgdk-pixbuf2.0-0 libxcomposite1 libxdamage1 libxrandr2 libgbm1 libgtk-4-1 libgraphene-1.0-0 libwoff1 libevent-2.1-7 libopus0 libsecret-1-0 libhyphen0 libmanette-0.2-0 libgles2 libsoup2.4 libpcre3 libvpx-dev
#           sudo npx playwright install-deps
  
#       - name: Fix PhantomJS Issue
#         run: |
#           npm uninstall phantomjs-prebuilt
#           npm install phantomjs-prebuilt@2.1.13
#           npm cache clear --force
#           npm install
          
#       - name: Debug Environment
#         run: |
#           python -m playwright --version
#           echo $PATH
          
#       - name: Run the scraper
#         run: |
#           python main.py
          
#       - name: Upload Logs
#         if: always()
#         uses: actions/upload-artifact@v4
#         with:
#           name: scraper-logs
#           path: scraper.log
#           retention-days: 7
      
#       - name: Cleanup
#         if: always()
#         run: |
#           rm -rf node_modules
#           rm -rf ~/.cache/ms-playwright
